---
title: "Final Exam"
author: "Jamie Duncan"
date: "09/12/2020"
output: html_document
---

```{r message=FALSE, warning=FALSE}
set.seed(123)
library(tidyverse)
library(kableExtra)
```


#### Section 1
##### Question 1
A scholar wants to research the effect of import competition on firms’ lobbying behavior. She gathers data on a series of firms. For each firm, she has a measure of imports in that firm’s sector and the number of times that the firm has lobbied a minister for protection. She regresses lobbying on imports and describes the results as a causal effect of imports on lobbying. Describe the assumptions she has to make for this claim to hold. Do you believe them?

##### Answer 1
She is assuming that there are not other factors that would impact the rate at which firms lobby ministers and the import rate. For example, the sector of a given firm, the political party of the minister, and where iumports are coming from might all explain away or nuance this purported causal effect. I would be more inclined to believe this claim if it were tested against a variety of potentially confounding factors and it was determined that this model was the best fit. Moreover, I would need to understand how the study was randomized before believing any causal claims/ estimates it might make.

##### Question 2
Another scholar conducted a survey with simple random sampling of 1,000 Canadians. He asked three demographic questions, and wants to combine them into a single variable with distinct values for all possible combinations. The number of response categories are:  
 - Race/ethnicity: 6 (White, South Asian, Chinese, Black, Filipino, Other)   
 - Gender: 3 (Male, Female, Non-binary/Other)   
 - Province/Territory: 13   
How many unique values of this variable are possible? Is he likely to find at least one respondent with each possible combination in his data? Why or why not?

##### Answer 2

```{r}
product <- choose(1000, 6) * choose(1000, 3) * choose(1000, 13)
lproduct <- lchoose(1000, 6) * lchoose(1000, 3) * lchoose(1000, 13)
formatC(product, format = "f", digits = 0)
lproduct


```

The number of possible combinations is so high that my brain can't comprehend. Likewise the chances of having one of every possible combination are even less comprehensible but are verrry close to zero.

##### Question 3
Imagine you are a professor in a Master’s program that is very demanding. You are planning to expand it, and so are reviewing your admissions data to try to make sure that the students you admit can succeed. Previously, students were admitted if the sum of their undergraduate GPA (on a 4 point scale) and the quality of their letters of recommendation (also on a 4 point scale) was greater than 5.5. You find that regressing the students Master’s GPA on their letter score produces a coefficient of -.15. How would you interpret this? As you expand the program, how would you use this information to reform the admissions process?

BONUS Simulate the admissions process described here if there is no relationship between letter quality and GPA. Plot the resulting distribution of GPA and letter quality among the admitted students.

##### Answer 3
The output of this binomial regression indicates that, on average, for each 1 point rise in an applicant's GPA, their letters will decrease by 0.15. In general, a higher GPA means that students have excelled in their coursework while good letters indicate that a student has a capacity to build relationships with more experienced academics. Both are essential qualities for success in a graduate program and in professional life. To me this is a prime case for the introduction of a more holistic analysis of applicants. Both the recommendation letters and in many cases the grades are the products of inconsistent and incomparable qualitative assessments. An above-average statistics student will have been graded differently than an above-average student in classics -- both could bring something valueable to a graduate social sciences program. A student who attended a small liberal arts college will look different than one who attended an enormous institution like U of T (in my view, there is a better chance the former can write effectively). In short, there is no guarantee that the data has been generated consistently. It is on this basis that I would recommend the admissions process move towards using these quantitative metrics to set a lower limit on admissions and then making further admissions decisions qualitatively on the basis of each candidate's personal, academic, and professional experiences.

##### BONUS Answer

```{r}



```


##### Question 4
A group of scholars ran a field experiment in which they gave voters information on politicians. In the control condition, they simply provided the names and party affiliations of candidates for a regional assembly on a postcard. In the treatment condition, the postcard also provided information about the candidates’ positions on a series of issues. They then observed whether the addressees of the postcards voted. Using the information below, calculate and interpret the p-value of the estimated average treatment effect (use the Normal approximation and a two-sided test).

 - $N_0$ = 10000
 - $N_1$ = 1000
 - $Y_0$ = 0.46
 - $Y_1$ = 0.5
 
##### Answer 4
```{r}

n0 <- 10000
n1 <- 1000
y0 <- 0.46
y1 <- 0.5


n0dist <- rbinom(n0, 1, y0)
n1dist <- rbinom(n1, 1, y1)

var(n0dist)
var(n1dist)


test <- t.test(n0dist, n1dist, alternative = "two.sided", var.equal = FALSE)

test
diff(test$estimate)


  
```
In this calculation, the estimated ATE is 0.04. The p-value of 0.011 is weakly significant. The confidence intervals do not include zero so we can reject the null hypothesis. This indicates that there is a small and weakly significant positive relationship associated with treatment.
 
##### Question 5
Since 1945 the Liberal party has been in power in Canada for 50 out of 76 years. If every year’s control is an independently and randomly generated binomial variable and my null hypothesis is that the Liberals and Conservatives are equally likely to win power, should I reject that null? You may do this in R or by hand.   

In that same period, there were 24 elections, of which Liberals won 15. If I believe that each of these results is independently distributed random variable, and my null hypothesis is again that the two parties are equally likely to win power, should I reject the null? You may do this in R or by hand. HINT: if you use R, it would be a good idea to look at the mu argument in t-test. Compare the two results and explain their relationship to one another.

##### Answer 5a

```{r}

liberals <- rbinom(10000, 76, prob = (50/76))
t.test(liberals, mu = 0.5 * 76)


```
We can reject the null hypothesis that there is an even chance of gaining power between the liberals and conservatives. The liberal mean of 50 is 12 higher than the null mean of 38, which is not included in the confidence intervals. The p-value indicates a highly significant positive relationship indicating the liberals are more likely to be in office.

##### Answer 5b

```{r}
liberals_el <- rbinom(10000, 24, prob = (15/24))
t.test(liberals_el, mu = 0.5 * 24)

```
We can continue to reject the null hypothesis that there is an even chance of gaining power between the liberals and conservatives. The liberal mean of 15 is 3 higher than the null mean of 12, which is not included in the confidence intervals. The p-value indicates a highly significant positive relationship indicating the liberals are more likely to be in officewin each election.


##### Question 6
Let $Y = {1,−1, 0, 0}$ and $X = {4,−2, 0,−2}$. Without using a computer, calculate $\hat{\alpha}$ and $\hat{\beta}$ using OLS.

##### Answer 6
$\hat{\alpha} = 0$ and $\hat{\beta} = 0$ meaning this was all for naught. See below for the most analogue calculation I could muster.


![alpha hat and beta hat calculated by hand](hatsbyhand.jpg)

##### Question 7
One technique for getting survey respondents to reveal attitudes or beliefs that might be stigmatized2 is to give them the following instructions: We will ask you a yes or no question. Before answering, flip a coin behind this screen. If comes up heads, answer “Yes.” If it is tails, answer honestly. Do not reveal the coin to the interviewer.  

That way, respondents can answer yes and the interviewer cannot tell whether a respondent who answers yes actually holds the attitude or belief in question or not.  

Assume that respondents follow this procedure correctly. How would you use a sample of responses obtained with this procedure to estimate the share of the population who answered yes? Now assume that you have reason to believe that 20% of the population holds that attitude. For an individual respondent who answered “Yes,” what should your belief be about the probability that that respondent holds the attitude?

##### Answer 7
This is a randomized response methodology. We know the probability of a truthful response in this case is 0.5. So if we take the proportion of people who say no and double it, we can then subtratc that number from 100 and have an accurate picture of how many respondents truthfully answered yes. For example, let's say we are asking people whether they participate in far-right internet forums if 40% of the respondents say no, that really means that 80% of truthful responses are no leaving us with 20% of respondents who do actually participate in far right internet forums.

##### Question 8
Pick a quantitative paper that makes a causal claim in your favorite research area. Describe and critically evaluate the authors’ identification strategy in 1-2 paragraphs. Provide proper citation so I can read the paper.

##### Answer 8
Terman, R. (2017). Islamophobia and media portrayals of Muslim women: A computational text analysis of US news coverage. **International Studies Quarterly, 61**(3), 489-502.

In this paper Terman uses 35 years of news coverage from **The New York Times** and **The Washington Post** to test two related hypotheses: "H1a:Muslim women are more likely to make the news if they live in societies that violate their rights. H1b:Non-Muslim women are more likely to make the news if they live in societies that respect their rights". and "H2:All else equal, coverage of Muslim women focuses more on “women's rights and gender discrimination” than coverage of non-Muslim women". Pairing structural topic modeling with a statistical analysis of key development metrics measuring gender equality, Terman makes the causal claim that American news coverage propagates perceptions that Muslims are inherently sexist. Terman cites literature on public opinion, media effects, and cultural threat theory but does not make any specific claims about media effects on public attitudes caused by this framing. Rather she claims that well documented stereotypes about Islam are reflected in US news as a because of confirmation bias.  

In testing H1, Terman pairs probit and negative binomial regressions to test the interaction effects between statistics on a country's women's rights record, whether it is located in the Middle East, the proportion of the population that is Muslim, and the quality of coverage that features women against the dependent variable of the likelihood of receiving media coverage. Terman concludes that "the effect of women's rights protections on the likelihood of coverage depends on whether the observation constitutes a Muslim (MENA) country. Muslim societies that violate women's rights garner special attention, while the reverse holds for non-Muslim societies." Terman also finds support for H2. This time regressing the percentage of coverage with a women's rights focus (as detected by the topic model) against a women's rights index and the proportion of the population that is Muslim. Terman finds that "US news media talk more about “Women's Rights and Gender Equality” if the reported country lies in the MENA region or has a larger Muslim population, regardless of the status of women's rights on the ground."

For both models, Terman includes a range of potentially confounding variables and alternative (and more simplistic) metrics to adress any potential critiques of the topic model. Terman's central causal claim that the coverage from two of the largest news outlets is impacted by orientalist and gendered confirmation bias is statistically supported. That causal claim is bolstered through Terman's work to situate it in a variety of related scholarship, which demonstrates the rigor of the assumptions underlying the study (that Muslims are stereotyped as more sexist than non-Muslims). 

##### Question 9
Consider a population $X \sim U(0.5, 3)$. If you randomly sampled N observations from that population, what is the expected value for the number of observations for which $X = 2$?     

Solving for the expected value of $z = \frac{1}{X}$ requires a bit of calculus, so let’s do the R way. For every N from 10 to 10,000, simulate a vector of X and calculate $\overline{z}$. Then, plot $\overline{z}$ across the values of N. What does it converge to?

##### Answer 9
```{r}



```

 
##### Question 10
This lawsuit (link) is an attempt by the Attorney General of Texas to overturn the presidential election results in Wisconsin, Michigan, Pennsylvania, and Georgia. Paragraphs 9-11 (page 6-7) contain some claims relevant to this class. How do you think they came up with the claim they make there? Does it seem plausible? Why or why not?

##### Answer 10
The misinformation captured in this lawsuit made it's way onto social media and now many people are writing about it. At first I was hoping it was a misuse of Zipf's law or something like that. Sadly it was more basic. Dr. Charles Cicchetti provided a declaration describing his "hypothesis testing and calculation of Z-scores and p-values" of the voting trends, comparing the early results with the results that came in many days later [Politifact](https://www.politifact.com/factchecks/2020/dec/10/facebook-posts/texas-lawsuit-statistics-fraud-wisconsin-michigan/). The most glaring flaw in Cicchetti's Declaration is his assumption that voter behaviour is uniformly distributed -- that voters in different places and of different political leanings will act the same way. The claim that the chances of Biden having won the four key states of Georgia, Michigan, Pennsylvania, and Wisconsin is less than 1 in 1 quadrillion rests on the erroneous assumption that the in-person votes counted on election day would have the same distribution as those that were mailed in and counted in the subsequent days. In this particular election, Democratic voters happened to be more in touch with the reality that this pandemic is dangerous. The Biden camp encouraged it's voters to mail in their ballots so they wouldn't die. This means that Democratic votes would have been concentrated in the post-election counts, thus explaining the so-called "blue wave". While the US electorate may be divided relatively evenly, that doesn't mean we can use `rbinom` to predict the election results.

#### Section 2
##### Question 1
We begin by loading the data and complete the following tasks. First, check if the dataset contains any missing values. Next, compute the mean of outcome (Y) by region without repeatedly using the mean() function.

##### Answer 1
```{r}
costs <- read.csv("admin_costs.csv")
summary(costs)
```

```{r message=FALSE, warning=FALSE}
costs %>%  
  group_by(region) %>% 
  summarise(mean(Y))

```

##### Question 2
Start by regressing spending on a dummy for treatment. What do you find? Is this plausibly causal? Why or why not?  
Repeat the regression while controlling for year fixed effects. Interpret the results.  
Finally, interact the treatment and the year fixed effects and interpret the results.  
Looking at the results from the third regression, and using only the coef function (not using the predict function), what is the predicted spending for a treated unit in 2010? Show your work.   
*Bonus* Put the result of all three regressions in a well-formatted table.

##### Answer 2
```{r}
mun_fit <- lm(Y ~ factor(treatment), data = costs)
summary(mun_fit)
```

```{r}
mun_fit2 <- lm(Y ~ factor(treatment)+ factor(year), data = costs)
summary(mun_fit2)
```

```{r}
mun_fit3 <- lm(Y ~ factor(treatment) * factor(year), data = costs)
summary(mun_fit3)
```

```{r message=FALSE, warning=FALSE, results='asis'}
stargazer(mun_fit, mun_fit2, mun_fit3)

```


##### Question 3
The authors employed the Difference-in-differences (DiD) approach to estimate the change in administrative costs in control and treatment municipalities, before and after the reform.  
Create a time-series plot of the mean outcome by year. The horizontal axis is the years whereas the vertical axis is the mean outcome. You should have two lines connecting data points (each data point should be marked by a symbol): one for the treatment group and the other for the control group. Add a vertical dashed line on the year 2007 so that the pre- and post-treatment periods are clear. Lastly, properly label x and y axies. Do not forget to use different colors and add text labels to differentiate two lines.

##### Question 4
What is the identification assumption for the DiD approach? Does the plot you created in the previous question confirm that the assumption is likely to hold in this application? Why or why not?

##### Question 5 
Using the data from years 2007 (the last year of pre-treatment period) and 2008 (the first year of posttreatment period), compute the DiD estimate of the effect of municipal merger on administrative costs. Report a point estimate as well as its 95% confidence interval. Briefly interpret the result.

##### Question 6
Above, we examined the validity of using the DiD estimator by a visual inspection. This question asks you to investigate the validity by calculating DiD estimates in pre-treatment periods (that is, conduct a placebo test). If the outcomes from both treated and control groups moved in tandem before the amalgamation happened, the DiD estimate should be zero. Follow the following steps to complete this question:  

1. Define a function named calc_did() that takes the following arguments: data (the dataframe used), pre_year (the pre-treatment time period used for the DiD estimation), and post_year (the posttreatment time period used for the DiD estimation). The calc_did() function returns a vector with three elements that correspond to the lower bound of the 95% confidence interval, the point estimate, and the upper bound of the 95% confidence interval.
2. Use the function that you defined in the Step 1 and confirm that your answer is the same as the previous question. Run calc_did(data = data, pre_year = 2007, post_year = 2008).
3. Check the following outcomes and briefly comment on the results: calc_did(data = data, pre_year = 2006, post_year = 2007) and calc_did(data = data, pre_year = 2005, post_year = 2006).
